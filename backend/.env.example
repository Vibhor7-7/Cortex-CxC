# CORTEX Backend Configuration
#
# SETUP INSTRUCTIONS FOR NEW CONTRIBUTORS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Install Ollama: https://ollama.com
# 3. Pull required models: ollama pull qwen2.5 && ollama pull nomic-embed-text
# 4. Start Ollama: ollama serve
# 5. No API keys required â€” fully local!

# Database Configuration
DATABASE_URL=sqlite:///./cortex.db

# Ollama Configuration (local LLM for summarization + embeddings)
# Requires: ollama serve running
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# UMAP Configuration
UMAP_N_NEIGHBORS=15
UMAP_MIN_DIST=0.1

# Clustering Configuration
N_CLUSTERS=5

# Server Configuration
HOST=0.0.0.0
PORT=8000
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Environment
ENVIRONMENT=development